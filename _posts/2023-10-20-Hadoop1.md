---
layout: post
title: 分布式Lab1
author: Young Sheep
header-style: text
catalog: true
tags:
  - Hadoop
  - 课程实验
---
# 实验主要步骤
## 通过VMware安装虚拟机
![](img/in-post/Pasted%20image%2020231111101214.png)
## 配置每个虚拟机的环境
- 设置虚拟机的网络为NAT模式
	![](/img/in-post/Pasted%20image%2020231111101141.png)
- 修改虚拟机的hosts文件
	```
	nano /etc/hosts
	```
	![](/img/in-post/Pasted%20image%2020231111103357.png)
- 分别修改各自的hostname
	```
	nano /etc/hostname
	```
	![](img/in-post/Pasted%20image%2020231111103527.png)
- 分别修改各自的网卡IP地址、掩码和网关
	```
	ip addr
	nano /etc/sysconfig/network-scripts/ifcfg-ens32
	```
    ![](/img/in-post/Pasted%20image%2020231111103724.png)
    > *<font color="red">坑:</font>*
    最后发现这里还需要设置DNS，否则后面就无法连接外部网络
    即添加 DNS1=114.114.114.114
- 最后ping一下其他虚拟机，查看网络是否ping通
	![](/img/in-post/Pasted%20image%2020231111104632.png)
## 安装JDK
- 通过yum在CentOS虚拟机中安装JAVA JDK1.8
	```
	yum install java-1.8.0-openjdk
	```
	>*<font color="red">坑:</font>*
	上述常规命令安装的openjdk默认只有JRE，但后续进行实验需要用到jar命令，必须安装JDK，因此需要安装 java-1.8.0-openjdk-devel
- 通过查看版本命令检测是否安装成功
	```
	java -version
	```
## 设置SSH无密码验证配置
- 在每个虚拟机上都生成SSH秘钥
	```
	ssh-keygen -t rsa
	```
-  将master的公钥移动到其他每个slave机器上
	```
	scp ~/.ssh/id_rsa.pub root@slave1:~/.ssh/authorized_keys
	scp ~/.ssh/id_rsa.pub root@slave2:~/.ssh/authorized_keys
	scp ~/.ssh/id_rsa.pub root@slave3:~/.ssh/authorized_keys
	scp ~/.ssh/id_rsa.pub root@slave4:~/.ssh/authorized_keys
	```
- 修改.ssh目录的权限为700 和修改.ssh/authorized_keys 的权限为600
	```
	chmod 700 ~/.ssh
	chmod 600 ~/.ssh/authorized_keys
	```
## 安装Hadoop
- 在/opt目录建立hadoop目录，通过Xftp拷贝hadoop-2.10.2.tar.gz
- 使用tar -zxvf解压 hadoop-2.10.2.tar.gz
## 配置Hadoop
- 编辑conf/hadoop-env.sh文件，JAVA_HOME设置成Java安装根路径
	```
	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.382.b05-1.el7_9.x86_64
	```
- 配置core-site.xml
	![](/img/in-post/Pasted%20image%2020231111110717.png)
- 配置hdfs-site.xml
	![](/img/in-post/Pasted%20image%2020231111110838.png)
- 配置mapred-site.xml
	![](/img/in-post/Pasted%20image%2020231111110959.png)
- 配置conf/masters和conf/slaves来设置主从结点
	masters:
	```
	master
	```
	salves:
	```
	salve1
	salve2
	salve3
	salve4
	```
## 初始化Hadoop
- 格式化hadoop
	```
	./bin/hadoop namenode -format
	```
	>*<font color="red">坑:</font>*
	格式化之后，每个节点会生成唯一标识符记录下来，如果再次格式化会导致节点失效，因此需要先手动删除name、data以及tmp文件夹下的文件再重新格式化。
- 启动hadoop
	```
	sbin/start-all.sh
	```
	![](/img/in-post/Pasted%20image%2020231111111913.png)
- 访问192.168.1.11:50070查看首页
	![](/img/in-post/Pasted%20image%2020231111112040.png)
